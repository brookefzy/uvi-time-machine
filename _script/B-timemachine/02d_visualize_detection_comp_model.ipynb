{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the object detection between YOLO and the Oneformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall set up\n",
    "ROOTFOLDER = \"/lustre1/g/geog_pyloo/05_timemachine\"\n",
    "PATH_PATH = \"{ROOTFOLDER}/GSV/gsv_rgb/{cityabbr}/gsvmeta/gsv_path.csv\"\n",
    "CURATED_FOLDER = f\"{ROOTFOLDER}/_curated\"\n",
    "TRANSFOM_FOLDER = f\"{ROOTFOLDER}/_transformed\"\n",
    "OBJECT_SOURCE_FOLDER = \"{CURATED_FOLDER}/{city_abbr}/*_objects.parquet\"\n",
    "GRAPHICS_FOLDER = f\"{CURATED_FOLDER}/graphics\"\n",
    "GRAPHICS_PATH = \"{GRAPHICS_FOLDER}/{city_abbr}.png\"\n",
    "if not os.path.exists(GRAPHICS_FOLDER):\n",
    "    os.makedirs(GRAPHICS_FOLDER)\n",
    "\n",
    "PATH_SEL = \"{PATH_TRANSFOM_FOLDER}/{city_abbr}.csv\"\n",
    "OBJECT_LS = [\n",
    "    \"person\",\n",
    "    \"car\",\n",
    "    \"truck\",\n",
    "    \"bus\",\n",
    "    \"bicycle\",\n",
    "    \"motorcycle\",\n",
    "    \"van\",\n",
    "]\n",
    "COLORS = {\n",
    "    \"person\": \"pink\",\n",
    "    \"car\": \"blue\",\n",
    "    \"truck\": \"red\",\n",
    "    \"bus\": \"green\",\n",
    "    \"bicycle\": \"purple\",\n",
    "    \"motorcycle\": \"orange\",\n",
    "    \"van\": \"yellow\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_path(city, object_list):\n",
    "    \"\"\"Get the path of the images with at least one person in the city\"\"\"\n",
    "    cityabbr = city.replace(\" \", \"\").lower()\n",
    "    df_path = pd.read_csv(PATH_PATH.format(ROOTFOLDER=ROOTFOLDER, cityabbr=cityabbr))\n",
    "    objfiles = glob.glob(OBJECT_SOURCE_FOLDER.format(CURATED_FOLDER=CURATED_FOLDER, city_abbr=cityabbr))[:1] # only use 2 files since we are just sampling the data\n",
    "    df = pd.concat([pd.read_parquet(f) for f in objfiles])\n",
    "\n",
    "    df_path['img'] = df_path['path'].apply(lambda x: x.split(\"/\")[-1])\n",
    "    # df_path_sel = df[df['object_name'].isin(object_list)].merge(df_path, on='img')\n",
    "    # get the image with most number of car and person in one frame\n",
    "    df = df[df['object_name'].isin(OBJECT_LS)].reset_index(drop=True)\n",
    "\n",
    "    df_summary = df.groupby([\"img\",\"object_name\"]).size().reset_index().rename(columns={0: \"count\"})\n",
    "    df_summary_sel = df_summary[df_summary['count']>2].sort_values(\"count\", ascending=True).groupby('object_name').head(2)\n",
    "    df_path_sel = df_summary_sel.merge(df_path, on='img')\n",
    "    return df_path_sel, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_image(df_path_sel, i):\n",
    "#     \"\"\"Visualize the image\"\"\"\n",
    "#     img = df_path_sel.iloc[i]['path']\n",
    "#     img_name = img.split(\"/\")[-1]\n",
    "#     object_name = df_path_sel.iloc[i]['object_name']\n",
    "#     detection = df[(df['img'] == img_name)&(df['object_name'] == object_name)].reset_index(drop=True)\n",
    "#     print(img_name)\n",
    "#     print(object_name)\n",
    "#     # draw a bounding box using the detection results\n",
    "#     img = plt.imread(img)\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.imshow(img)\n",
    "#     for i in range(detection.shape[0]):\n",
    "#         # the results are x1, y1, x2, y2\n",
    "#         x1, y1, x2, y2 = detection.iloc[i][['x1', 'y1', 'x2', 'y2']]\n",
    "#         x, y = x1, y1\n",
    "#         w, h = x2 - x1, y2 - y1\n",
    "#         rect = plt.Rectangle((x, y), w, h, linewidth=1, edgecolor=COLORS[object_name], facecolor='none')\n",
    "#         ax.add_patch(rect)\n",
    "#         # remove the axis\n",
    "#         ax.axis('off')\n",
    "#     plt.show()\n",
    "    \n",
    "def visualize_all_images(df_path_sel, df, cityabbr):\n",
    "    df_path_sel = df_path_sel.sort_values(\"object_name\")\n",
    "    n_obj = df_path_sel['object_name'].nunique()\n",
    "    fig, axes = plt.subplots(2, n_obj, figsize=(10,4))\n",
    "    for j, obj in enumerate(OBJECT_LS):\n",
    "        df_path_sel_obj = df_path_sel[df_path_sel['object_name'] == obj].reset_index(drop=True)\n",
    "        for i in range(df_path_sel_obj.shape[0]):\n",
    "            img = plt.imread(df_path_sel_obj.iloc[i]['path'])\n",
    "            axes[i,j].set_title(obj)\n",
    "            axes[i, j].imshow(img)\n",
    "            detection = df[(df['img'] == df_path_sel_obj.iloc[i]['img'])&(df['object_name'] == obj)].reset_index(drop=True)\n",
    "            for k in range(detection.shape[0]):\n",
    "                x1, y1, x2, y2 = detection.iloc[k][['x1', 'y1', 'x2', 'y2']]\n",
    "                x, y = x1, y1\n",
    "                w, h = x2 - x1, y2 - y1\n",
    "                rect = plt.Rectangle((x, y), w, h, linewidth=1, edgecolor=COLORS[obj], facecolor='none')\n",
    "                axes[i, j].add_patch(rect)\n",
    "            axes[i, j].axis('off')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(GRAPHICS_PATH.format(GRAPHICS_FOLDER=GRAPHICS_FOLDER, city_abbr=cityabbr), dpi=150)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample_city \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew York\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHong Kong\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokyo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLondon\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNairobi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBangkok\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m----> 2\u001b[0m     df_path_sel, df \u001b[38;5;241m=\u001b[39m \u001b[43mget_city_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_city\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOBJECT_LS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     visualize_all_images(df_path_sel, df, cityabbr\u001b[38;5;241m=\u001b[39msample_city\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mget_city_path\u001b[0;34m(city, object_list)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the path of the images with at least one person in the city\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m cityabbr \u001b[38;5;241m=\u001b[39m city\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m----> 4\u001b[0m df_path \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH_PATH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mROOTFOLDER\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mROOTFOLDER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcityabbr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcityabbr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m objfiles \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(OBJECT_SOURCE_FOLDER\u001b[38;5;241m.\u001b[39mformat(CURATED_FOLDER\u001b[38;5;241m=\u001b[39mCURATED_FOLDER, city_abbr\u001b[38;5;241m=\u001b[39mcityabbr))[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;66;03m# only use 2 files since we are just sampling the data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mread_parquet(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m objfiles])\n",
      "File \u001b[0;32m/scr/u/yuanzf/anaconda3/envs/py312/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scr/u/yuanzf/anaconda3/envs/py312/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scr/u/yuanzf/anaconda3/envs/py312/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/scr/u/yuanzf/anaconda3/envs/py312/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen codecs>:319\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for sample_city in [\"New York\", \"Hong Kong\", \"Tokyo\",\"London\", \"Nairobi\", \"Bangkok\"]:\n",
    "    df_path_sel, df = get_city_path(sample_city, OBJECT_LS)\n",
    "    visualize_all_images(df_path_sel, df, cityabbr=sample_city.lower().replace(\" \", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_city = \"Hong Kong\"\n",
    "df_path_sel, df = get_city_path(sample_city, OBJECT_LS)\n",
    "# visualize_all_images(df_path_sel, cityabbr = sample_city.lower().replace(\" \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the image to curated folder\n",
    "curated_folder = \"/lustre1/g/geog_pyloo/05_timemachine/_curated/c_oneformer_example\"\n",
    "os.makedirs(curated_folder, exist_ok=True)\n",
    "\n",
    "for path in df_path_sel['path'].values:\n",
    "    os.system(f\"cp {path} {curated_folder}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_image = df_path_sel['path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cd /scr/u/yuanzf/_playground/OneFormer/demo\n",
      "\n",
      "python demo.py --config-file ../configs/ade20k/swin/oneformer_swin_large_bs16_160k.yaml --input /lustre1/g/geog_pyloo/05_timemachine/GSV/gsv_rgb/hongkong/img_rgb/1_1/6/7/0B88Hq6vNG9GItyhzw5CNA_0.jpg --output /lustre1/g/geog_pyloo/05_timemachine/_curated/c_oneformer_example --task panoptic --opts MODEL.IS_TRAIN False MODEL.IS_DEMO True MODEL.WEIGHTS ../ckpt/250_16_swin_l_oneformer_ade20k_160k.pth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_checkpoint  = \"../ckpt/250_16_swin_l_oneformer_ade20k_160k.pth\"\n",
    "curated_folder = \"/lustre1/g/geog_pyloo/05_timemachine/_curated/c_oneformer_example\"\n",
    "bash_c = f\"\"\"\n",
    "cd /scr/u/yuanzf/_playground/OneFormer/demo\n",
    "\n",
    "python demo.py --config-file ../configs/ade20k/swin/oneformer_swin_large_bs16_160k.yaml \\\n",
    "--input {path_to_image} \\\n",
    "--output {curated_folder} \\\n",
    "--task panoptic \\\n",
    "--opts MODEL.IS_TRAIN False MODEL.IS_DEMO True MODEL.WEIGHTS {path_to_checkpoint}\n",
    "\"\"\"\n",
    "print(bash_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
