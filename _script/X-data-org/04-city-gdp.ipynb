{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import os\n",
    "import gspread\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAIKEY')\n",
    "\n",
    "\n",
    "RAW_FOLDER = \"D:/Dropbox (Personal)/Personal Work/_Projects2023/01_city-never-was/_data/_raw/_city_profiles\"\n",
    "TRANSFORM_FOLDER = \"D:/Dropbox (Personal)/Personal Work/_Projects2023/01_city-never-was/_data/_transformed/t_city_profiles\"\n",
    "if not os.path.exists(TRANSFORM_FOLDER):\n",
    "    os.makedirs(TRANSFORM_FOLDER)\n",
    "FILENAME = \"r_city_gdp_wikipidia.xlsx\"\n",
    "\n",
    "df = pd.read_excel(f\"{RAW_FOLDER}/{FILENAME}\")\n",
    "df[\"pop_metro\"] = df['pop_metro'].apply(lambda x: float(x.replace(\",\", \"\").strip()) if type(x) == str else x)\n",
    "df['gdp_billion'] = df['gdp_billion'].apply(lambda x: float(x.replace(\",\", \"\").strip()) if type(x) == str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gspread\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_url(url, SHEET_NAME):\n",
    "    SHEET_ID = url.split(\"/\")[5]\n",
    "    spreadsheet = gc.open_by_key(SHEET_ID)\n",
    "    worksheet = spreadsheet.worksheet(SHEET_NAME)\n",
    "    rows = worksheet.get_all_records()\n",
    "    df_spread = pd.DataFrame(rows)\n",
    "    return df_spread, worksheet\n",
    "\n",
    "serviceaccount = \"../../google_drive_personal.json\"\n",
    "gc = gspread.service_account(filename=serviceaccount)\n",
    "GC_URL = \"https://docs.google.com/spreadsheets/d/1o5gFmZPUoDwrrbfE6M26uJF3HnEZll02ivnOxP6K6Xw/edit?usp=sharing\"\n",
    "\n",
    "SHEETNAME = \"select_city_classifier\"\n",
    "city_meta, other_worksheet = read_url(GC_URL, SHEETNAME)\n",
    "city_meta = city_meta[city_meta['City']!=''].reset_index(drop = True)\n",
    "city_meta[\"country_clean\"] = np.where(city_meta[\"Country\"].isin([\"USA\", \"United States\"]), \n",
    "                                      \"United States of America\",\n",
    "                                      city_meta[\"Country\"]\n",
    "                                     )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list_1 = city_meta['City'].tolist()\n",
    "city_list_2 = df['Metro'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_city(city, city_list):\n",
    "    \n",
    "    for c in city_list:\n",
    "        if city.lower().replace(\" \", \"\") in c.lower().replace(\" \", \"\").replace(\"-\",\"\"):\n",
    "            return c\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped = []\n",
    "for city in city_list_1:\n",
    "    if city =='Sao Paulo':\n",
    "        mapped.append('Greater São Paulo')\n",
    "    elif city =='Portland, OR':\n",
    "        mapped.append('Portland-South Portland, ME MSA')\n",
    "    else:\n",
    "        mapped.append(find_city(city, city_list_2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\"City\": city_list_1, \"city_wiki\": mapped})\n",
    "df_results = city_meta[[\"City\",\"country_clean\",'State/Province','urban_pop']].merge(df_results, on = 'City')\\\n",
    "    .merge(df[['Metro','gdp_billion', 'pop_metro','source_year']], \n",
    "                 left_on = 'city_wiki', \n",
    "                 right_on = 'Metro', how = 'left').drop(\"city_wiki\", axis = 1)\\\n",
    "                     .rename(columns = {'gdp_billion':'gdp_billion_metro','pop_metro':'gdp_pop_metro'})\n",
    "                     \n",
    "df_results['gdp_per_cap'] = df_results['gdp_billion_metro'].astype(float)/df_results['gdp_pop_metro']*1_000_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_results.to_csv(os.path.join(TRANSFORM_FOLDER, \"t_city_gdp_mapping.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Country level gdp per capita to fill in the nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "TRANSFORM_FOLDER = \"D:/Dropbox (Personal)/Personal Work/_Projects2023/01_city-never-was/_data/_transformed/t_city_profiles\"\n",
    "CURATED_FOLDER = \"D:/Dropbox (Personal)/Personal Work/_Projects2023/01_city-never-was/_data/_curated/city_profiles\"\n",
    "RAW_FOLDER = \"D:/Dropbox (Personal)/Personal Work/_commondata/_world_data/03_global_gdp\"\n",
    "if not os.path.exists(CURATED_FOLDER):\n",
    "    os.makedirs(CURATED_FOLDER)\n",
    "\n",
    "FILENAME = \"imf-dm-export-20240514.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"{RAW_FOLDER}/{FILENAME}\").rename(columns = {\"GDP per capita, current prices\\n (U.S. dollars per capita)\":\"country\"})\n",
    "df.columns = [str(x) for x in df.columns]\n",
    "df = df[[\"country\", \"2022\"]].rename(columns ={ \"2022\":\"gdp_per_cap_country_2022\"})\n",
    "\n",
    "\n",
    "country_name_mapping = {\n",
    "    'United States':'United States of America',\n",
    "    'Türkiye, Republic of':'Turkey',\n",
    "    'Korea, Republic of': 'Republic of Korea',\n",
    "}\n",
    "df['admin_mapped'] = df['country'].apply(lambda x: country_name_mapping[x] if x in country_name_mapping.keys() else x)\n",
    "\n",
    "df_stage1 = pd.read_csv(os.path.join(TRANSFORM_FOLDER, \"t_city_gdp_mapping.csv\"))\n",
    "df_stage1['admin_mapped'] = np.where(\n",
    "    df_stage1['City']=='Taipei',\n",
    "    'Taiwan Province of China',\n",
    "    df_stage1['country_clean']\n",
    ")\n",
    "df_stage1['admin_mapped'] = np.where(\n",
    "    df_stage1['City']=='Hong Kong',\n",
    "    'Hong Kong SAR',\n",
    "    df_stage1['admin_mapped']\n",
    ")\n",
    "df_stage1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stage2 = df_stage1.merge(df, on = 'admin_mapped', how = 'left')\n",
    "df_stage2[df_stage2['gdp_per_cap_country_2022'].isnull()]['country_clean'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage2.drop([\"admin_mapped\", 'country'], axis = 1)\\\n",
    "    .to_csv(os.path.join(CURATED_FOLDER, \"c_city_gdp.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
