{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import netcdf\n",
    "import netCDF4\n",
    "ROOTFOLDER = \"D:/Dropbox (Personal)/Personal Work/_Projects2023/01_city-never-was/_data\"\n",
    "RAW_PATH = \"D:/Dropbox (Personal)/Personal Work/_commondata/_world_data/01_carbon_emission_ffdas/ffdas_flux_2013_2015.nc.gz/ffdas_flux_2015b.nc/ffdas_flux_2015.nc\"\n",
    "TRANSFORM_FOLDER = \"D:/Dropbox (Personal)/Personal Work/_Projects2023/01_city-never-was/_data/_transformed/t_city_profiles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['latitude', 'latitude_edge', 'longitude', 'longitude_edge', 'flux'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc = netCDF4.Dataset(RAW_PATH)\n",
    "nc.variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the netcdf to a pandas dataframe\n",
    "df = pd.DataFrame(nc.variables[\"flux\"][:])\n",
    "df[\"latitude\"] = nc.variables[\"latitude\"][:]\n",
    "df.set_index('latitude', inplace=True)\n",
    "df.columns = nc.variables[\"longitude\"][:]\n",
    "# df[\"longitude\"] = nc.variables[\"longitude\"][:]\n",
    "df = df.stack().reset_index().rename(columns={0: 'flux','level_1':'longitude'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_FOLDER = f\"{ROOTFOLDER}/_raw/_city_profiles\"\n",
    "df.to_csv(os.path.join(RAW_FOLDER, \"r_ffdas_flux_2015.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate to each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading boundary files:  127\n"
     ]
    }
   ],
   "source": [
    "# load all zone area for selected city\n",
    "ROOTFOLDER = \"D:/Dropbox (Personal)/Personal Work/_Projects2023/01_city-never-was/_data\"\n",
    "RAW_BOUND_FOLDER = f\"{ROOTFOLDER}/_raw/r_boundary_osm\"\n",
    "TRANSFORM_FOLDER = f\"{ROOTFOLDER}/_transformed/t_city_profiles/\"\n",
    "boundfiles = [f for f in os.listdir(RAW_BOUND_FOLDER) if f.endswith('.geojson')]\n",
    "print(\"loading boundary files: \", len(boundfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_lower</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accra</td>\n",
       "      <td>POLYGON ((-0.28413 5.57195, -0.28386 5.57090, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amsterdam</td>\n",
       "      <td>MULTIPOLYGON (((4.72878 52.40071, 4.75607 52.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>antwerp</td>\n",
       "      <td>POLYGON ((4.21758 51.37389, 4.21826 51.37221, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>astrakhan</td>\n",
       "      <td>POLYGON ((47.87112 46.26966, 47.87152 46.26632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>athens</td>\n",
       "      <td>MULTIPOLYGON (((22.89876 36.19485, 22.89888 36...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_lower                                           geometry\n",
       "0      accra  POLYGON ((-0.28413 5.57195, -0.28386 5.57090, ...\n",
       "1  amsterdam  MULTIPOLYGON (((4.72878 52.40071, 4.75607 52.3...\n",
       "2    antwerp  POLYGON ((4.21758 51.37389, 4.21826 51.37221, ...\n",
       "3  astrakhan  POLYGON ((47.87112 46.26966, 47.87152 46.26632...\n",
       "4     athens  MULTIPOLYGON (((22.89876 36.19485, 22.89888 36..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allbound = []\n",
    "for f in boundfiles:\n",
    "    temp = gpd.read_file(os.path.join(RAW_BOUND_FOLDER, f))\n",
    "    temp['city_lower'] = f.split(\".\")[0]\n",
    "    temp = temp[['city_lower','geometry']].to_crs(\"EPSG:4326\")\n",
    "    allbound.append(temp)\n",
    "allbound = pd.concat(allbound).reset_index(drop = True)\n",
    "allbound.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['accra', 'amsterdam', 'antwerp', 'astrakhan', 'athens', 'auckland',\n",
       "       'bacolod', 'bangalore', 'bangkok', 'belgrade', 'belohorizonte',\n",
       "       'berezniki', 'berlin', 'bogotÃ¡', 'boston', 'brussels', 'budapest',\n",
       "       'buenosaires', 'capetown', 'cebucity', 'chicago', 'cirebon',\n",
       "       'cleveland', 'cochabamba', 'copenhagen', 'culiacan', 'curitiba',\n",
       "       'delhi', 'denver', 'detroit', 'dhaka', 'dubai', 'dzerzhinsk',\n",
       "       'florianopolis', 'fukuoka', 'gaborone', 'gainesville', 'gombe',\n",
       "       'guadalajara', 'guatemalacity', 'hindupur', 'hongkong', 'houston',\n",
       "       'hyderabad', 'ilheus', 'istanbul', 'jaipur', 'jakarta', 'jalna',\n",
       "       'jequie', 'jerusalem', 'johannesburg', 'kampala', 'kanpur',\n",
       "       'kaunas', 'kigali', 'killeen', 'kozhikode', 'kualalumpur', 'kyiv',\n",
       "       'lagos', 'lemans', 'lima', 'london', 'losangeles', 'madrid',\n",
       "       'malegaon', 'manchester', 'manila', 'medan', 'metromanila',\n",
       "       'mexicocity', 'miami', 'milan', 'minneapolis', 'modesto',\n",
       "       'montreal', 'moscow', 'mumbai', 'munich', 'nagoya', 'nairobi',\n",
       "       'newyork', 'okayama', 'palembang', 'palermo', 'palmas', 'parbhani',\n",
       "       'parepare', 'paris', 'philadelphia', 'portland', 'pune', 'quito',\n",
       "       'rajshahi', 'raleigh', 'reynosa', 'ribeiraopreto', 'riodejaneiro',\n",
       "       'rome', 'rovno', 'saidpur', 'saintpetersburg', 'sanfrancisco',\n",
       "       'santiago', 'saopaulo', 'seoul', 'sheffield', 'singapore',\n",
       "       'sitapur', 'stockholm', 'sydney', 'taipei', 'telaviv',\n",
       "       'thessaloniki', 'tokyo', 'toledo', 'toronto', 'tyumen',\n",
       "       'valledupar', 'victoria', 'vienna', 'vijayawada', 'warsaw',\n",
       "       'wellington', 'yamaguchi', 'zwolle'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allbound['city_lower'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the data\n",
    "# temp = gpd.read_file(os.path.join(RAW_BOUND_FOLDER, \"athens.geojson\"))\n",
    "# temp.crs = \"EPSG:2100\"\n",
    "# temp = temp.to_crs(\"EPSG:4326\")\n",
    "# temp.to_file(os.path.join(RAW_BOUND_FOLDER, \"athens.geojson\"), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "allbound.to_file(os.path.join(TRANSFORM_FOLDER, \"t_city_boundary.geojson\"), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuanzfan\\AppData\\Local\\Temp\\ipykernel_39932\\844500843.py:5: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  df_buffer['geometry'] = df_buffer.geometry.buffer(0.1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(RAW_FOLDER, \"r_ffdas_flux_2015.csv\"))\n",
    "df = df[df['flux']>0].reset_index(drop = True)\n",
    "df = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs=\"EPSG:4326\")\n",
    "df_buffer = df.copy()\n",
    "df_buffer['geometry'] = df_buffer.geometry.buffer(0.1) # original data is at 0.1 degree resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "seldf = gpd.sjoin(df_buffer[['flux','geometry','latitude','longitude']], allbound, how = 'inner'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first exproti\n",
    "seldfagg = seldf.groupby('city_lower').agg({'flux':['sum', 'mean','count']}).reset_index().rename(\n",
    "    columns = {'sum':'total_flux', 'mean':'mean_flux','count':'n_points'})\n",
    "\n",
    "seldfagg.columns = seldfagg.columns.droplevel(0)\n",
    "seldfagg.columns = ['city_lower', 'total_flux', 'mean_flux','flux_n_points']\n",
    "seldfagg.sort_values(\"total_flux\", ascending=False).to_csv(os.path.join(TRANSFORM_FOLDER, \"t_ffdas_flux_2015.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data to hexagon\n",
    "import h3pandas\n",
    "h3_df = []\n",
    "for res in [6,9,12]:\n",
    "    temp = seldf.h3.polyfill(resolution = res)\n",
    "    h3_df.append(pd.DataFrame(temp, columns = [f\"h3_{res}\"]))\n",
    "    print(f\"resolution {res} done\")\n",
    "\n",
    "h3_df = pd.concat(h3_df, axis = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "seldf.drop(['geometry', 'index_right', 'latitude', 'longitude'], axis = 1).to_csv(os.path.join(TRANSFORM_FOLDER, \"t_ffdas_flux_hex_2015.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
