{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e932552-75ff-4349-b92f-971d02b391e1",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "1. Move the data to corresponding folder per dataset structure here: https://docs.ultralytics.com/datasets/classify/\n",
    "```\n",
    "cifar-10-/\n",
    "|\n",
    "|-- train/\n",
    "|   |-- airplane/\n",
    "|   |   |-- 10008_airplane.png\n",
    "|   |   |-- 10009_airplane.png\n",
    "|   |   |-- ...\n",
    "|   |\n",
    "|   |-- automobile/\n",
    "|   |   |-- 1000_automobile.png\n",
    "|   |   |-- 1001_automobile.png\n",
    "|   |   |-- ...\n",
    "|   |\n",
    "|   |-- bird/\n",
    "|   |   |-- 10014_bird.png\n",
    "|   |   |-- 10015_bird.png\n",
    "|   |   |-- ...\n",
    "|   |\n",
    "|   |-- ...\n",
    "|\n",
    "|-- test/\n",
    "|   |-- airplane/\n",
    "|   |   |-- 10_airplane.png\n",
    "|   |   |-- 11_airplane.png\n",
    "|   |   |-- ...\n",
    "|   |\n",
    "|   |-- automobile/\n",
    "|   |   |-- 100_automobile.png\n",
    "|   |   |-- 101_automobile.png\n",
    "|   |   |-- ...\n",
    "|   |\n",
    "|   |-- bird/\n",
    "|   |   |-- 1000_bird.png\n",
    "|   |   |-- 1001_bird.png\n",
    "|   |   |-- ...\n",
    "|   |\n",
    "|   |-- ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e0328a-ab19-457b-bcd7-c2a958637730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "TRANSFORMED_FOLDER = \"/lustre1/g/geog_pyloo/05_timemachine/_transformed/t_classifier\"\n",
    "CURATED_FOLDER = \"/lustre1/g/geog_pyloo/05_timemachine/_curated/c_classifier\"\n",
    "if not os.path.exists(CURATED_FOLDER):\n",
    "    os.makedirs(CURATED_FOLDER)\n",
    "    \n",
    "YOLOFOLDER = \"/lustre1/g/geog_pyloo/05_timemachine/_transformed/t_classifier_img_yolo8\"\n",
    "TRAIN_FOLDER = os.path.join(YOLOFOLDER, \"train\")\n",
    "TEST_FOLDER = os.path.join(YOLOFOLDER, \"test\")\n",
    "for fl in [YOLOFOLDER, TRAIN_FOLDER, TEST_FOLDER]:\n",
    "    if not os.path.exists(fl):\n",
    "        os.makedirs(fl)\n",
    "        \n",
    "        \n",
    "train_file_name = \"c_train.parquet\"\n",
    "test_file_name = \"c_test.parquet\"\n",
    "train_df = pd.read_parquet(os.path.join(CURATED_FOLDER, train_file_name))\n",
    "test_df = pd.read_parquet(os.path.join(CURATED_FOLDER, test_file_name))\n",
    "\n",
    "\n",
    "        \n",
    "dataset = {\n",
    "    \"train\":train_df,\n",
    "    \"test\":test_df}\n",
    "\n",
    "for folder in ['train', 'test']:\n",
    "    print(f\"working on the {folder} data\")\n",
    "    for city in tqdm(train_df['city'].unique()):\n",
    "        city_folder = os.path.join(YOLOFOLDER, folder, city)\n",
    "        if not os.path.exists(city_folder):\n",
    "            os.makedirs(city_folder)\n",
    "            print(f\"start to copy data for city {city}\")\n",
    "            data = dataset[folder]\n",
    "            temp = data[data['city']==city].reset_index(drop = True)\n",
    "            for path in tqdm(temp['path'].values):\n",
    "                img_name = path.split(\"/\")[-1]\n",
    "                shutil.copy(path, cityfolder)\n",
    "            print(f\"{city} is done\")\n",
    "            print(\"*\"*100)\n",
    "\n",
    "# # load the large train and test dataset and reoganize them\n",
    "# files = glob.glob(TRANSFORMED_FOLDER+\"/*.csv\")\n",
    "# train_df= []\n",
    "# test_df = []\n",
    "# for f in tqdm(files):\n",
    "#     temp = pd.read_csv(f)\n",
    "#     temp['data_group'] = temp['data_group'].apply(lambda x: x.replace('sel','test'))\n",
    "#     train_df.append(temp[temp['data_group']=='train'])\n",
    "#     test_df.append(temp[temp['data_group']=='test'])\n",
    "\n",
    "# train_df = pd.concat(train_df).reset_index(drop = True)\n",
    "# test_df = pd.concat(test_df).reset_index(drop = True)\n",
    "# train_df[['path', 'data_group','city','label']].to_parquet(os.path.join(CURATED_FOLDER, train_file_name), index = False)\n",
    "# test_df[['path', 'data_group','city','label']].to_parquet(os.path.join(CURATED_FOLDER, test_file_name), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d2d41-3cc7-407b-9bae-9f4348ab5c37",
   "metadata": {},
   "source": [
    "# Test training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bbc9d38-43d3-4379-80cd-946a5439adf4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44334"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "YOLOFOLDER = \"/lustre1/g/geog_pyloo/05_timemachine/_transformed/t_classifier_img_yolo8\"\n",
    "files = glob.glob(YOLOFOLDER+'/*/*/*')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22cada9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_type\n",
       "jpg    44334\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'path':files})\n",
    "df['file_type'] = df['path'].apply(lambda x: x.split(\"/\")[-1].split(\".\")[-1])\n",
    "df.groupby('file_type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434f84de-8a7a-4247-9d21-397b2a204aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-cls.pt to 'yolov8n-cls.pt'...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.28M/5.28M [00:00<00:00, 14.1MB/s]\n",
      "New https://pypi.org/project/ultralytics/8.2.2 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.145 üöÄ Python-3.8.17 torch-2.0.1+cu117 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/mnt/03_gsv/t_classifier_img_yolo8, epochs=10, patience=50, batch=16, imgsz=400, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train2\n",
      "Overriding model.yaml nc=1000 with nc=109\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    469869  ultralytics.nn.modules.head.Classify         [256, 109]                    \n",
      "YOLOv8n-cls summary: 99 layers, 1577917 parameters, 1577917 gradients, 3.5 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train2', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:00<00:00, 15.9MB/s]\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "WARNING ‚ö†Ô∏è imgsz=[400] must be multiple of max stride 32, updating to [416]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Found no valid file for the classes Bacolod, Bangalore, Bangkok, Belgrade, Belo Horizonte, Berezniki, Berlin, Bogot√°, Boston, Brussels, Budapest, Buenos Aires, Capetown, Cebu City, Chicago, Cleveland, Cochabamba, Copenhagen, Culiacan, Curitiba, Delhi, Denver, Dhaka, Dubai, Fukuoka, Gaborone, Gainesville, FL, Gombe, Guadalajara, Guatemala City, Hindupur, Hong Kong, Houston, Hyderabad, Ilheus, Istanbul, Jaipur, Jakarta, Jalna, Jerusalem, Johannesburg, Kampala, Kaunas, Kigali, Killeen, Kozhikode, Kuala Lumpur, Kyiv, Lagos, Le Mans, Lima, London, Los Angeles, Madrid, Manchester, Manila, Medan, Metro Manila, Mexico City, Miami, Milan, Minneapolis, Modesto, Montreal, Mumbai, Munich, Nagoya, Nairobi, Okayama, Palembang, Palermo, Parbhani, Paris, Portland, OR, Pune, Quito, Rajshahi, Raleigh, Reynosa, Ribeirao Preto, Rio de Janeiro, Rome, Rovno, Saidpur, Saint Petersburg, San Francisco, Santiago, Sao Paulo, Seoul, Sitapur, Sydney, Taipei, Tel Aviv, Thessaloniki, Tokyo, Toledo, Toronto, Tyumen, Victoria, Vienna, Vijayawada, Warsaw, Wellington, Zwolle. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolov8n-cls.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# load a pretrained model (recommended for training)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mYOLOFOLDER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.8/site-packages/ultralytics/engine/model.py:377\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.8/site-packages/ultralytics/engine/trainer.py:192\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.8/site-packages/ultralytics/engine/trainer.py:276\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m world_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_ddp(world_size)\n\u001b[0;32m--> 276\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.8/site-packages/ultralytics/engine/trainer.py:240\u001b[0m, in \u001b[0;36mBaseTrainer._setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Dataloaders\u001b[39;00m\n\u001b[1;32m    239\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(world_size, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRANK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dataloader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.8/site-packages/ultralytics/models/yolo/classify/train.py:76\u001b[0m, in \u001b[0;36mClassificationTrainer.get_dataloader\u001b[0;34m(self, dataset_path, batch_size, rank, mode)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns PyTorch DataLoader with transforms to preprocess images for inference.\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(rank):  \u001b[38;5;66;03m# init dataset *.cache only once if DDP\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m loader \u001b[38;5;241m=\u001b[39m build_dataloader(dataset, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworkers, rank\u001b[38;5;241m=\u001b[39mrank)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Attach inference transforms\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.8/site-packages/ultralytics/models/yolo/classify/train.py:71\u001b[0m, in \u001b[0;36mClassificationTrainer.build_dataset\u001b[0;34m(self, img_path, mode, batch)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mClassificationDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.8/site-packages/ultralytics/data/dataset.py:229\u001b[0m, in \u001b[0;36mClassificationDataset.__init__\u001b[0;34m(self, root, args, augment, cache)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, root, args, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    220\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    Initialize YOLO object with root, image size, augmentations, and cache settings.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m        cache (bool | str | optional): Cache setting, can be True, False, 'ram' or 'disk'. Defaults to False.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m augment \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39mfraction \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1.0\u001b[39m:  \u001b[38;5;66;03m# reduce training fraction\u001b[39;00m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[:\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples) \u001b[38;5;241m*\u001b[39m args\u001b[38;5;241m.\u001b[39mfraction)]\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.8/site-packages/torchvision/datasets/folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    303\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    308\u001b[0m ):\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.8/site-packages/torchvision/datasets/folder.py:145\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m    144\u001b[0m classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_classes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot)\n\u001b[0;32m--> 145\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextensions \u001b[38;5;241m=\u001b[39m extensions\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.8/site-packages/torchvision/datasets/folder.py:189\u001b[0m, in \u001b[0;36mDatasetFolder.make_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_to_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# prevent potential bug since make_dataset() would use the class_to_idx logic of the\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# find_classes() function, instead of using that of the find_classes() method, which\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;66;03m# is potentially overridden and thus could have a different logic.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe class_to_idx parameter cannot be None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.8/site-packages/torchvision/datasets/folder.py:102\u001b[0m, in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m         msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported extensions are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextensions\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28misinstance\u001b[39m(extensions,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(extensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(msg)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m instances\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes Bacolod, Bangalore, Bangkok, Belgrade, Belo Horizonte, Berezniki, Berlin, Bogot√°, Boston, Brussels, Budapest, Buenos Aires, Capetown, Cebu City, Chicago, Cleveland, Cochabamba, Copenhagen, Culiacan, Curitiba, Delhi, Denver, Dhaka, Dubai, Fukuoka, Gaborone, Gainesville, FL, Gombe, Guadalajara, Guatemala City, Hindupur, Hong Kong, Houston, Hyderabad, Ilheus, Istanbul, Jaipur, Jakarta, Jalna, Jerusalem, Johannesburg, Kampala, Kaunas, Kigali, Killeen, Kozhikode, Kuala Lumpur, Kyiv, Lagos, Le Mans, Lima, London, Los Angeles, Madrid, Manchester, Manila, Medan, Metro Manila, Mexico City, Miami, Milan, Minneapolis, Modesto, Montreal, Mumbai, Munich, Nagoya, Nairobi, Okayama, Palembang, Palermo, Parbhani, Paris, Portland, OR, Pune, Quito, Rajshahi, Raleigh, Reynosa, Ribeirao Preto, Rio de Janeiro, Rome, Rovno, Saidpur, Saint Petersburg, San Francisco, Santiago, Sao Paulo, Seoul, Sitapur, Sydney, Taipei, Tel Aviv, Thessaloniki, Tokyo, Toledo, Toronto, Tyumen, Victoria, Vienna, Vijayawada, Warsaw, Wellington, Zwolle. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n-cls.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=YOLOFOLDER, epochs=10, imgsz=416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fd697b-bdc8-490b-b01c-284d1d24881d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
