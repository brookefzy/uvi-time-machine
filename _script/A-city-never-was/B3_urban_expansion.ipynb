{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51a9bb9-160d-47fa-8321-c899fdd73278",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "0. Check how many cities are in the 200 city project\n",
    "1. Compare the GSV panoid and check whether each urban expansion area contains enough sample\n",
    "2. Label the GSV by expansion period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a8051e-f083-40f5-a047-2755d075fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)\n",
    "from utils.gsvload import GSVSummary\n",
    "from shapely.geometry import Point\n",
    "\n",
    "PFOLDER = \"/lustre1/g/geog_pyloo/05_timemachine/_transformed/t_urban_expansion/t_urban_expansion\"\n",
    "ALLFILES = os.listdir(PFOLDER)\n",
    "RAW_FOLDER_ROOT = \"/lustre1/g/geog_pyloo/05_timemachine/_raw\"\n",
    "# TGT_FILE = \"gsv_pano_label.csv\" \n",
    "TGT_FILE = \"{cityabbrlower}_meta.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b1d5e-2b3e-4607-bbde-e241380fc047",
   "metadata": {},
   "source": [
    "## 1. Check how many cities intersect with the urban expansion project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d826c5-8540-4e42-9215-bc73f94ded7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expdf = pd.read_csv(os.path.join(RAW_FOLDER_ROOT, \"Areas_and_Densities_Table_1.csv\"))[1:]\n",
    "expdf = expdf[expdf['City Name'].notnull()].reset_index(drop = True)\n",
    "expdf['city_name_short'] = expdf['City Name'].apply(lambda x: x.split(\",\")[0].lower().replace(\" \", \"\"))\n",
    "# expdf['city_name_short'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d7c08c-0911-4587-9861-fede3f820670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "GSV_FOLDER = \"/lustre1/g/geog_pyloo/05_timemachine/GSV/gsv_rgb/\"\n",
    "GSV_PANO_LS = glob.glob(GSV_FOLDER + \"*/gsvmeta/gsv_pano_label.csv\")\n",
    "city_with_data = set([x.split(\"/\")[-3] for x in GSV_PANO_LS])\n",
    "len(city_with_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e530c826-d34f-4289-877c-39f705c46361",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unavailable = [\"cairo\",  # too few images\n",
    "               \"hochiminhcity\", \n",
    "               \"tehran\", # too few images\n",
    "              ]\n",
    "city_to_label = city_with_data.intersection(set(expdf['city_name_short'].unique()))\n",
    "city_to_label = [x for x in city_to_label if not x in unavailable]\n",
    "len(city_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11cf6e4d-801e-4a16-8add-1c732a03ac32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City Name</th>\n",
       "      <th>city_name_short</th>\n",
       "      <th>Country</th>\n",
       "      <th>Urban Extent Population</th>\n",
       "      <th>with GSV downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accra</td>\n",
       "      <td>accra</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>1,307,784</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Addis Ababa</td>\n",
       "      <td>addisababa</td>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>1,445,701</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>ahmedabad</td>\n",
       "      <td>India</td>\n",
       "      <td>3,737,723</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahvaz</td>\n",
       "      <td>ahvaz</td>\n",
       "      <td>Iran</td>\n",
       "      <td>698,310</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>alexandria</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>2,558,891</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Yulin, Guangxi</td>\n",
       "      <td>yulin</td>\n",
       "      <td>China</td>\n",
       "      <td>250,302</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Zhengzhou, Henan</td>\n",
       "      <td>zhengzhou</td>\n",
       "      <td>China</td>\n",
       "      <td>1,256,956</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Zhuji, Zhejiang</td>\n",
       "      <td>zhuji</td>\n",
       "      <td>China</td>\n",
       "      <td>367,695</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Zunyi, Guizhou</td>\n",
       "      <td>zunyi</td>\n",
       "      <td>China</td>\n",
       "      <td>24,968</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Zwolle</td>\n",
       "      <td>zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>79,950</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            City Name city_name_short      Country Urban Extent Population   \n",
       "0               Accra           accra        Ghana               1,307,784  \\\n",
       "1         Addis Ababa      addisababa     Ethiopia               1,445,701   \n",
       "2           Ahmedabad       ahmedabad        India               3,737,723   \n",
       "3               Ahvaz           ahvaz         Iran                 698,310   \n",
       "4          Alexandria      alexandria        Egypt               2,558,891   \n",
       "..                ...             ...          ...                     ...   \n",
       "195    Yulin, Guangxi           yulin        China                 250,302   \n",
       "196  Zhengzhou, Henan       zhengzhou        China               1,256,956   \n",
       "197   Zhuji, Zhejiang           zhuji        China                 367,695   \n",
       "198    Zunyi, Guizhou           zunyi        China                  24,968   \n",
       "199            Zwolle          zwolle  Netherlands                  79,950   \n",
       "\n",
       "     with GSV downloaded  \n",
       "0                   True  \n",
       "1                  False  \n",
       "2                  False  \n",
       "3                  False  \n",
       "4                  False  \n",
       "..                   ...  \n",
       "195                False  \n",
       "196                False  \n",
       "197                False  \n",
       "198                False  \n",
       "199                 True  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new google sheet to check which of the 200 cities already captured\n",
    "toupdate = expdf[['City Name','city_name_short','Country','Urban Extent Population']].reset_index(drop = True)\n",
    "toupdate['with GSV downloaded'] = toupdate['city_name_short'].isin(city_to_label)\n",
    "toupdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c1deed-2986-48b0-aade-25b66dbd93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# random select the images within 5.5km of the city center\n",
    "gcloudapi = \"AIzaSyCohhLdvyTC0UsGriQ9j-rU8pRln5wVVG8\"\n",
    "serviceaccount = \"../../google_drive_personal.json\"\n",
    "import gspread\n",
    "\n",
    "# from oauth2client.service_account import ServiceAccountCredentials\n",
    "gc = gspread.service_account(filename=serviceaccount)\n",
    "\n",
    "def read_url(url, SHEET_NAME):\n",
    "    SHEET_ID = url.split(\"/\")[5]\n",
    "    spreadsheet = gc.open_by_key(SHEET_ID)\n",
    "    worksheet = spreadsheet.worksheet(SHEET_NAME)\n",
    "    rows = worksheet.get_all_records()\n",
    "    df_spread = pd.DataFrame(rows)\n",
    "    return df_spread, worksheet\n",
    "\n",
    "def create_new_gsheet(url, sheet_name, rows, cols):\n",
    "    \"\"\"\n",
    "    Create a new sheet in the Google Sheet by URL and return the worksheet object.\n",
    "\n",
    "    :param url: the URL of the Google Sheet\n",
    "\n",
    "    :param sheet_name: the name of the new sheet to create\n",
    "\n",
    "    :param rows: the number of rows in the new sheet\n",
    "\n",
    "    :param cols: the number of columns in the new sheet\n",
    "\n",
    "    :return worksheet: the Google Sheet worksheet object\n",
    "\n",
    "    \"\"\"\n",
    "    SHEET_ID = url.split(\"/\")[5]\n",
    "    spreadsheet = gc.open_by_key(SHEET_ID)\n",
    "    worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=rows, cols=cols)\n",
    "    return worksheet\n",
    "\n",
    "\n",
    "url = \"https://docs.google.com/spreadsheets/d/1o5gFmZPUoDwrrbfE6M26uJF3HnEZll02ivnOxP6K6Xw/edit?usp=sharing\"\n",
    "SHEETNAME = \"urban_expansion\"\n",
    "# city_meta, other_worksheet = read_url(url, SHEETNAME)\n",
    "# create a new sheet in the same file\n",
    "# worksheet = create_new_gsheet(url, SHEETNAME, 210, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23c33a92-e033-4a63-8824-99072c2ad929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1o5gFmZPUoDwrrbfE6M26uJF3HnEZll02ivnOxP6K6Xw',\n",
       " 'updatedRange': 'urban_expansion!A1:E201',\n",
       " 'updatedRows': 201,\n",
       " 'updatedColumns': 5,\n",
       " 'updatedCells': 1005}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# worksheet.update(\n",
    "#     [toupdate.columns.values.tolist()] + toupdate.values.tolist()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b53379d-13ae-4007-9cee-365cd284ae99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# after manual checking the availability of gsv, check number of cities needs to be downloaded\n",
    "exp_meta, worksheet = read_url(url, SHEETNAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14d2b882-4244-4fb5-8052-1e219488bcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['City Name', 'city_name_short', 'Country', 'Urban Extent Population',\n",
       "       'with GSV downloaded', 'with GSV online'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33c3fd6c-025b-4d3a-9937-a65bdcc58a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "with GSV downloaded  with GSV online\n",
       "FALSE                FALSE              72\n",
       "                     TRUE               95\n",
       "TRUE                 TRUE               33\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_download = exp_meta.groupby(['with GSV downloaded', 'with GSV online']).size()\n",
    "to_download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab40df9-b344-4c82-afe1-4a4b266600cc",
   "metadata": {},
   "source": [
    "# Load data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9f548cc-bd4f-465b-9d33-584e913f0a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "META_FILE = \"{citylower}_meta.csv\"\n",
    "def load_area(city):\n",
    "    city_abbr = city.lower().replace(\" \", \"_\")\n",
    "    GLOBAL_CRS = \"EPSG:4326\"\n",
    "    \n",
    "    meta_file= META_FILE.format(citylower = city_abbr.replace(\"_\", \"\"))\n",
    "    citysummary = GSVSummary(city)\n",
    "    gsv_meta_folder = citysummary.metafolder\n",
    "    \n",
    "    meta_df = pd.read_csv(os.path.join(gsv_meta_folder, meta_file))\n",
    "    if \"ring\" in meta_df.columns:\n",
    "        print(\"Data already processed.\")\n",
    "        return None\n",
    "\n",
    "    else:\n",
    "        if city_abbr == \"hong_kong\":\n",
    "            geofilename = 'hong_kong,_hong_kong.geojson' # edge case\n",
    "        elif city_abbr == \"taipei\":\n",
    "            geofilename = 'taipei,_taiwan.geojson'\n",
    "        else:\n",
    "            geofilename = city_abbr + \".geojson\"\n",
    "        area = gpd.read_file(os.path.join(PFOLDER, geofilename))\n",
    "        meta_gdf = gpd.GeoDataFrame(meta_df, \n",
    "                                    geometry = [Point(x,y) for x,y in zip(meta_df['lon'], meta_df['lat'])])\n",
    "        meta_gdf.crs = GLOBAL_CRS\n",
    "        meta_intersect = gpd.sjoin(\n",
    "            meta_gdf[['panoid', 'geometry']], \n",
    "            area[[\"geometry\", \"ring\"]],\n",
    "        )\n",
    "        meta_update = meta_df.merge(meta_intersect[['panoid', 'ring']], on = 'panoid', how = 'left')\n",
    "\n",
    "        print(meta_file)\n",
    "        meta_update.drop_duplicates([\"path\", \"angle\"]).to_csv(\n",
    "            os.path.join(gsv_meta_folder, meta_file), \n",
    "                       index = False)\n",
    "        print(\"Data recevied\")\n",
    "        return meta_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c4144c2-82cb-4671-8283-5be4e8328388",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "city_to_label_ori = expdf[expdf['city_name_short'].isin(city_to_label)]['City Name'].unique()\n",
    "city_to_label_ori = [x.split(\",\")[0] for x in city_to_label_ori]\n",
    "print(len(city_to_label_ori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43ef2666-b4fd-4539-99cd-7daa18dfe641",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vienna_meta.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:44<00:00, 44.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data recevied\n",
      "Need to debug:  Vienna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:45, 18.94s/it]                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already processed.\n",
      "Need to debug:  Vienna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:46, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already processed.\n",
      "Need to debug:  Vienna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:47,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already processed.\n",
      "Need to debug:  Vienna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:47,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already processed.\n",
      "Need to debug:  Vienna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:48,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already processed.\n",
      "Need to debug:  Vienna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:49,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already processed.\n",
      "Need to debug:  Vienna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:49,  7.09s/it]\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m remaincity \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVienna\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m city \u001b[38;5;129;01min\u001b[39;00m tqdm(remaincity):\n\u001b[0;32m----> 5\u001b[0m     load_area(city)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeed to debug: \u001b[39m\u001b[38;5;124m\"\u001b[39m, city)\n\u001b[1;32m      7\u001b[0m     remaincity\u001b[38;5;241m.\u001b[39mappend(city)\n",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m, in \u001b[0;36mload_area\u001b[0;34m(city)\u001b[0m\n\u001b[1;32m      7\u001b[0m citysummary \u001b[38;5;241m=\u001b[39m GSVSummary(city)\n\u001b[1;32m      8\u001b[0m gsv_meta_folder \u001b[38;5;241m=\u001b[39m citysummary\u001b[38;5;241m.\u001b[39mmetafolder\n\u001b[0;32m---> 10\u001b[0m meta_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(gsv_meta_folder, meta_file))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mring\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m meta_df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData already processed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m         nrows\n\u001b[1;32m   1706\u001b[0m     )\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:812\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:873\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:848\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:859\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:2025\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "remaincity = ['Vienna']\n",
    "for city in tqdm(remaincity):\n",
    "\n",
    "    load_area(city)\n",
    "    print(\"Need to debug: \", city)\n",
    "    remaincity.append(city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aecec9f-8318-4a52-9ec1-aa41bb035e42",
   "metadata": {},
   "source": [
    "# Summarize data within each ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b7acb-68b0-4e88-bec8-6b69f4eeda62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo311",
   "language": "python",
   "name": "geo311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
