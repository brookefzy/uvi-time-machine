{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate the risk of pedestrian by:\n",
    "total number of person observed in the panoids (location) with car/total number of person observed in all images within the hexagon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)\n",
    "import h3\n",
    "import geopandas as gpd\n",
    "import argparse\n",
    "\n",
    "ROOTFOLDER = \"/lustre1/g/geog_pyloo/05_timemachine\"\n",
    "PANO_PATH = \"{ROOTFOLDER}/GSV/gsv_rgb/{cityabbr}/gsvmeta/gsv_pano.csv\"\n",
    "PATH_PATH = \"{ROOTFOLDER}/GSV/gsv_rgb/{cityabbr}/gsvmeta/gsv_path.csv\"\n",
    "CURATED_FOLDER = f\"{ROOTFOLDER}/_curated\"\n",
    "META_PATH = \"{ROOTFOLDER}/GSV/gsv_rgb/{cityabbr}/gsvmeta/{cityabbr}_meta.csv\"\n",
    "EXFOLDER = os.path.join(CURATED_FOLDER, \"c_object_crossectional\")\n",
    "EXFOLDER_LONG = os.path.join(CURATED_FOLDER, \"c_object_longitudinal\")\n",
    "EXFOLDER_SEG_LONG = os.path.join(CURATED_FOLDER, \"c_seg_longitudinal_all\")\n",
    "if not os.path.exists(EXFOLDER):\n",
    "    os.makedirs(EXFOLDER)\n",
    "if not os.path.exists(EXFOLDER_LONG):\n",
    "    os.makedirs(EXFOLDER_LONG)\n",
    "# YEAR_GROUP = [\"2015-2018\", \"2020-2023\"]\n",
    "YEAR_GROUP = [\"<2014\", \"2014-2015\", \"2016-2017\", \"2018-2019\", \"2020-2021\", \"2022-2023\"]\n",
    "column_map = {\n",
    "    \"<2014\": [\n",
    "        2007,\n",
    "        2008,\n",
    "        2009,\n",
    "        2010,\n",
    "        2011,\n",
    "        2012,\n",
    "        2013,\n",
    "    ],\n",
    "    \"2014-2015\": [2014, 2015],\n",
    "    \"2016-2017\": [2016, 2017],\n",
    "    \"2018-2019\": [2018, 2019],\n",
    "    \"2020-2021\": [2020, 2021],\n",
    "    \"2022-2023\": [2022, 2023],\n",
    "}\n",
    "\n",
    "OBJECT_SOURCE_FOLDER = \"{CURATED_FOLDER}/{city_abbr}/*_objects.parquet\"\n",
    "\n",
    "# variables may change later\n",
    "# res = 9  # resolution of hexagon\n",
    "min_num_pano = 2  # minimum number of panoid per each hexagon to avoid sampling bias\n",
    "exportfolder = f\"{EXFOLDER}/exposure_measure\"\n",
    "os.makedirs(exportfolder, exist_ok=True)\n",
    "\n",
    "def get_hex_basics(city_abbr, res):\n",
    "    # read all object files and concat them into one df\n",
    "    df_pano = pd.read_csv(PANO_PATH.format(ROOTFOLDER=ROOTFOLDER, cityabbr=city_abbr))\n",
    "    df_path = pd.read_csv(PATH_PATH.format(ROOTFOLDER=ROOTFOLDER, cityabbr=city_abbr))\n",
    "    # only keep the panoid that has a path\n",
    "    df_pano_inner = df_pano[\n",
    "        df_pano[\"panoid\"].isin(df_path[\"panoid\"].unique())\n",
    "    ].reset_index(drop=True)\n",
    "    print(df_pano_inner.shape[0], \"out of \", df_pano.shape[0], \"panoids have path\")\n",
    "    df_pano_inner[\"hex_id\"] = df_pano_inner.apply(\n",
    "        lambda x: h3.geo_to_h3(x[\"lat\"], x[\"lon\"], res), axis=1\n",
    "    )\n",
    "\n",
    "    # keep these hex\n",
    "    df_all_keep = df_pano_inner[(df_pano_inner[\"year\"] >= 2014)].reset_index(drop=True)\n",
    "    print(df_all_keep.shape[0], \"panoids are kept\")\n",
    "    # assign the year_group; skip for now\n",
    "\n",
    "    # get number of panoid per hex per year\n",
    "    df_all_keep_hex = (\n",
    "        df_all_keep.groupby([\"hex_id\", \"year\"])[\"panoid\"]\n",
    "        .nunique()\n",
    "        .reset_index(name=\"panoid_n\")\n",
    "    )\n",
    "    return df_all_keep_hex, df_all_keep\n",
    "## Incorporate into the 02b_object_detect_summary.py\n",
    "\n",
    "def get_exposure(city, res):\n",
    "    city_abbr = city.lower().replace(\" \", \"\")\n",
    "    df_all_keep_hex, df_all_keep = get_hex_basics(city_abbr, res)\n",
    "    print(\"Done with basic hexagon setup\")\n",
    "\n",
    "    # process the prediction results\n",
    "    objfiles = glob.glob(\n",
    "        OBJECT_SOURCE_FOLDER.format(CURATED_FOLDER=CURATED_FOLDER, city_abbr=city_abbr)\n",
    "    )\n",
    "    if len(objfiles) == 0:\n",
    "        print(\"No object files found for\", city)\n",
    "    df = pd.concat([pd.read_parquet(f) for f in objfiles])\n",
    "    df[\"panoid\"] = df[\"img\"].apply(lambda x: x[:22])\n",
    "    # object specific processing\n",
    "    variable_ls_kep = [\n",
    "        \"person\",\n",
    "        \"car\",\n",
    "        \"truck\",\n",
    "        \"bus\",\n",
    "        \"bicycle\",\n",
    "        \"motorcycle\",\n",
    "        \"train\",\n",
    "        \"fire hydrant\",\n",
    "        \"van\",\n",
    "        \"bench\",\n",
    "        \"chair\",\n",
    "        \"table\",\n",
    "        \"traffic light\",\n",
    "        \"stop sign\",\n",
    "    ]\n",
    "\n",
    "    df_sel = (\n",
    "        df[df[\"object_name\"].isin(variable_ls_kep)]\n",
    "        .groupby([\"panoid\", \"object_name\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"n\")\n",
    "    )\n",
    "    # get the panoid that have car/truck/bus and person observed at the same time\n",
    "    df_sel['with_vehicle'] = df_sel.groupby('panoid')['object_name'].transform(lambda x: x.isin(['car', 'truck', 'bus','van']).any())\n",
    "\n",
    "    object_summary = \\\n",
    "        df_all_keep[[\"panoid\", \"year\", \"hex_id\"]]\\\n",
    "        .merge(df_sel[df_sel['object_name'].isin(['person','motorcycle', 'bicycle'])], on=\"panoid\", how=\"inner\")\n",
    "    object_summary_update = object_summary.groupby(['hex_id', 'object_name','with_vehicle'])['n'].sum().reset_index()\n",
    "    object_summary_wide = object_summary_update.pivot(columns = ['object_name','with_vehicle'], index = 'hex_id', values = 'n').reset_index().fillna(0)\n",
    "    # # flatten the column names\n",
    "    object_summary_wide.columns = ['_'.join([str(x) for x in col]).strip() for col in object_summary_wide.columns.values]\n",
    "    object_summary_wide['person_total'] = object_summary_wide['person_False'] + object_summary_wide['person_True']\n",
    "    object_summary_wide['bicycle_total'] = object_summary_wide['bicycle_False'] + object_summary_wide['bicycle_True']\n",
    "    object_summary_wide['motorcycle_total'] = object_summary_wide['motorcycle_False'] + object_summary_wide['motorcycle_True']\n",
    "    object_summary_wide['person_exposure'] = object_summary_wide['person_True'] / object_summary_wide['person_total']\n",
    "    object_summary_wide['bicycle_exposure'] = object_summary_wide['bicycle_True'] / object_summary_wide['bicycle_total']\n",
    "    object_summary_wide['motorcycle_exposure'] = object_summary_wide['motorcycle_True'] / object_summary_wide['motorcycle_total']\n",
    "    # object_summary_wide.to_parquet(f\"{exportfolder}/{city_abbr}_res={res}.parquet\")\n",
    "    print(\"Done with crossectional object exposure: \", city)\n",
    "    return object_summary_wide\n",
    "    \n",
    "def load_all_cities(res):\n",
    "    city_ls = (\n",
    "            pd.read_csv(\"/home/yuanzf/uvi-time-machine/_script/city_meta.csv\")[\"City\"]\n",
    "            .unique()\n",
    "            .tolist()\n",
    "        )\n",
    "    \n",
    "    for res in [8,9,12]:\n",
    "        fulldf = []\n",
    "        for city in city_ls:\n",
    "            print(\"Processing\", city)\n",
    "            try:\n",
    "                object_summary_wide = get_exposure(city, res)\n",
    "            except:\n",
    "                print(\"Error in processing\", city)\n",
    "            object_summary_wide['city'] = city\n",
    "            fulldf.append(object_summary_wide)\n",
    "        fulldf = pd.concat(fulldf).reset_index(drop = True)\n",
    "        fulldf.to_parquet(f\"{exportfolder}/exposure_res={res}.parquet\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
